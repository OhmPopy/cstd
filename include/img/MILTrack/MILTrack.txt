MIL TRACK
算法流程
1. 第一帧进行人脸检测，记录矩形框尺度以及左上角点坐标和右下角点坐标
2. 从特征池中随机选择M 个随机特征(包括位置、尺度和类型)，具体注意事项
见函数randomMFeatures.m，采用的是5 类haar 特征，A:左右，B:上下，C:
左中右，D:对角，E:上中下
3. 在距当前矩形位置左上角点一定距离范围内随机选择负样本和正样本(只记
录左上角点坐标)，见函数randomSelectSample.m
4. 计算每一个样本对应的M 个候选弱分类器,以及初始化/更新每个特征对于所
有正样本或所有负样本的均值和标准差，这一步数据量较大容易出错要仔细
写，见函数candidateWeakClf.m
函数内的流程解释以及弱分类器形式：
1) 计算每个样本对应每个特征的特征值，保存于变量AllFeatures
2) 以及初始化/更新每个特征对于所有正样本或所有负样本的均值和标准差
3) 求弱分类器输出，弱分类器形式为：
hm(xn) = log[p(yn =1|fm (xn)) / p(yn =0|fm (xn))]，其中fm (xn)表示样本xn对应
的第m个特征，yn =1 为正样本标记，yn =0 为负样本标记，按照bayes条件概率公
式P(B|A)=P(B)P(A|B)/P(A)展开，并让p(yn =1) == p(yn =0)，得
hm(xn) = log[p(fm (xn)| yn =1) / p(fm (xn)| yn =0)]
其中p(fm (xn)| yn =1) 服从均值为μ1，标准差为σ1的高斯分布，p(fm (xn)| yn =0)
服从均值为μ2，标准差为σ2的高斯分布
写成代码的形式为：
h_candidateWeakClf = log((P_F_1+0.000000001)/(P_F_0+0.000000001))，加
0.000000001 是为了防止log 无意义的情况发生
5. 从M 个候选弱分类器中选择K 个最佳弱分类器
每个负样本单独做为一个包，所有正样本做为一个包，计算样本包的概率
P_main(列向量，行数为：负样本数+1)，里面用到了S 型函数，所有负样本包标
记为0，正样本包标记为1，存储于Label_y(维数与P_main 相同)
这个地方用文字叙述比较麻烦，还是见程序吧，思路不复杂，或者我讲讲，
要注意的地方如下：
1) 计算正样本包的概率时用到NOISY-OR 模型
P_main_1 = 1 ? П(1 ? p_each),其中p_each 为正样本包中的每个样本的概
率，NOISY-OR 模型意思为只要序列中一个元素为真则整个序列就为真，
也就是说正样本包中只要有一个样本为真正的正样本则整个正样本包则
P_main 就为真(接近1 或等于1)
2) 第m 个特征对应的损失函数(错误率)为：
L(m,1)=abs(sum(Label_y.*log(P_main+0.000000001) +
(1-Label_y).*log(1-P_main + 0.000000001),1))
6. 进入下一帧进行搜索
1) 在距上一帧矩形位置左上角点一定距离范围内随机选择一些候选位置(如
500 个)，采用半固定半随机策略，即在原位置较近区域内固定100~300
个位置，其余的位置在稍远区域内随机选择，这样可以避免完全随机产
生位置而使只有很少一部分位置在上一帧位置的左上角点的邻近区域
内。见函数randomSelectSample_for_result.m
2) 将500 个候选位置对应的样本用K 个弱分类器(组成一个强分类器)分类，
对应强分类器输出最大的位置(矩形左上角点坐标)即为最终结果,见函数
compute_reult.m
重复步骤3~6
